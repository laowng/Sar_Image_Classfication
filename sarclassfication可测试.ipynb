{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "\n",
    "def conv_weight(in_planes, planes, kernel_size=3, stride=1, padding=0, bias=False, transpose=False):\n",
    "    \" init convolutions parameters, necessary due to code architecture \"\n",
    "    if transpose:\n",
    "        params = nn.ConvTranspose2d(in_planes, planes, kernel_size=kernel_size, stride=stride,\n",
    "                                    padding=padding, bias=bias).weight.data\n",
    "    else:\n",
    "        params = nn.Conv2d(in_planes, planes, kernel_size=kernel_size, stride=stride,\n",
    "                           padding=padding, bias=bias).weight.data\n",
    "    return params\n",
    "\n",
    "\n",
    "class Complex(nn.Module):\n",
    "    def __init__(self, real=None, imag=None):\n",
    "        super(Complex, self).__init__()\n",
    "        self.real = real\n",
    "        if imag is None and real is not None:\n",
    "            self.imag = torch.zeros_like(self.real)\n",
    "        elif imag is None and real is None:\n",
    "            self.imag = None\n",
    "        else:\n",
    "            self.imag = imag\n",
    "        if self.real is not None:\n",
    "            self.shape = self.real.shape\n",
    "            self.size = self.real.size\n",
    "        else:\n",
    "            self.shape = None\n",
    "            self.size = None\n",
    "\n",
    "    def mag(self):\n",
    "        return torch.sqrt(self.real ** 2 + self.imag ** 2)\n",
    "\n",
    "    def phase(self):\n",
    "        return torch.atan2(self.imag, self.real)\n",
    "\n",
    "    def from_polar(self, mag, phase):\n",
    "        self.real = mag * torch.cos(phase)\n",
    "        self.imag = mag * torch.sin(phase)\n",
    "        return\n",
    "\n",
    "    def view(self, *params):\n",
    "        return Complex(self.real.view(*params), self.imag.view(*params))\n",
    "\n",
    "    def __repr__(self):\n",
    "        # print(f'Complex Variable containing:\\nreal:\\n{self.real}imaginary:\\n{self.imag}') <- does'nt work\n",
    "        return ''\n",
    "\n",
    "\n",
    "class C_convtranspose2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        super(C_convtranspose2d, self).__init__()\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.weight_real = nn.Parameter(\n",
    "            conv_weight(in_channels, out_channels, kernel_size, stride, padding, transpose=True), requires_grad=True)\n",
    "        self.weight_imag = nn.Parameter(\n",
    "            conv_weight(in_channels, out_channels, kernel_size, stride, padding, transpose=True), requires_grad=True)\n",
    "\n",
    "    def forward(self, complex):\n",
    "        x_ = F.conv_transpose2d(complex.real, self.weight_real, stride=self.stride, padding=self.padding) - \\\n",
    "             F.conv_transpose2d(complex.imag, self.weight_imag, stride=self.stride, padding=self.padding)\n",
    "        y_ = F.conv_transpose2d(complex.imag, self.weight_real, stride=self.stride, padding=self.padding) + \\\n",
    "             F.conv_transpose2d(complex.real, self.weight_imag, stride=self.stride, padding=self.padding)\n",
    "        return Complex(x_, y_)\n",
    "\n",
    "\n",
    "class C_conv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super(C_conv2d, self).__init__()\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.weight_real = nn.Parameter(conv_weight(in_channels, out_channels, kernel_size, stride, padding),\n",
    "                                        requires_grad=True)\n",
    "        self.weight_imag = nn.Parameter(conv_weight(in_channels, out_channels, kernel_size, stride, padding),\n",
    "                                        requires_grad=True)\n",
    "\n",
    "    def forward(self, complex):\n",
    "        x_ = F.conv2d(complex.real, self.weight_real, stride=self.stride, padding=self.padding) - \\\n",
    "             F.conv2d(complex.imag, self.weight_imag, stride=self.stride, padding=self.padding)\n",
    "        y_ = F.conv2d(complex.imag, self.weight_real, stride=self.stride, padding=self.padding) + \\\n",
    "             F.conv2d(complex.real, self.weight_imag, stride=self.stride, padding=self.padding)\n",
    "\n",
    "        return Complex(x_, y_)\n",
    "\n",
    "\n",
    "class C_BatchNorm2d(nn.Module):\n",
    "    def __init__(self, num_features, affine=True, epsilon=1e-4, check=False, \\\n",
    "                 momentum=0.1, track_running_stats=True):\n",
    "        super(C_BatchNorm2d, self).__init__()\n",
    "        self.check = check\n",
    "        self.affine = affine\n",
    "        self.epsilon = epsilon\n",
    "        self.momentum = momentum\n",
    "        self.track_running_stats = track_running_stats\n",
    "\n",
    "        if self.affine:\n",
    "            self.bias_real = Parameter(torch.Tensor(num_features), requires_grad=True)\n",
    "            self.bias_imag = Parameter(torch.Tensor(num_features), requires_grad=True)\n",
    "\n",
    "            self.gamma_rr = Parameter(torch.Tensor(num_features), requires_grad=True)\n",
    "            self.gamma_ri = Parameter(torch.Tensor(num_features), requires_grad=True)\n",
    "            self.gamma_ii = Parameter(torch.Tensor(num_features), requires_grad=True)\n",
    "        else:\n",
    "            self.register_parameter('bias_real', None)\n",
    "            self.register_parameter('bias_imag', None)\n",
    "\n",
    "            self.register_parameter('gamma_rr', None)\n",
    "            self.register_parameter('gamma_ri', None)\n",
    "            self.register_parameter('gamma_ii', None)\n",
    "\n",
    "        if self.track_running_stats:\n",
    "            self.register_buffer('running_mean_real', torch.zeros(num_features))\n",
    "            self.register_buffer('running_mean_imag', torch.zeros(num_features))\n",
    "\n",
    "            self.register_buffer('running_Vrr', torch.ones(num_features) / float(np.sqrt(2.0)))\n",
    "            self.register_buffer('running_Vii', torch.ones(num_features) / float(np.sqrt(2.0)))\n",
    "            self.register_buffer('running_Vri', torch.zeros(num_features))\n",
    "\n",
    "            self.register_buffer('num_batches_tracked', torch.zeros(1))\n",
    "        else:\n",
    "            self.register_buffer('running_mean_real', None)\n",
    "            self.register_buffer('running_mean_imag', None)\n",
    "\n",
    "            self.register_buffer('running_Vrr', None)\n",
    "            self.register_buffer('running_Vii', None)\n",
    "            self.register_buffer('running_Vri', None)\n",
    "\n",
    "            self.register_buffer('num_batches_tracked', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_running_stats(self):\n",
    "        if self.track_running_stats:\n",
    "            self.running_mean_real.zero_()\n",
    "            self.running_mean_imag.zero_()\n",
    "\n",
    "            self.running_Vrr.fill_(1.0 / float(np.sqrt(2.0)))\n",
    "            self.running_Vii.fill_(1.0 / float(np.sqrt(2.0)))\n",
    "            self.running_Vri.zero_()\n",
    "\n",
    "            self.num_batches_tracked.zero_()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.reset_running_stats()\n",
    "        if self.affine:\n",
    "            nn.init.constant(self.bias_real.data, 0.0)\n",
    "            nn.init.constant(self.bias_imag.data, 0.0)\n",
    "\n",
    "            nn.init.constant(self.gamma_rr.data, float(np.sqrt(0.5)))\n",
    "            nn.init.constant(self.gamma_ri.data, float(np.sqrt(0.5)))\n",
    "            nn.init.constant(self.gamma_ii.data, float(np.sqrt(0.5)))\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return '{num_features}, eps={eps}, momentum={momentum}, affine={affine}, ' \\\n",
    "               'track_running_stats={track_running_stats}'.format(**self.__dict__)\n",
    "\n",
    "    def forward(self, complex):\n",
    "        real = complex.real\n",
    "        imag = complex.imag\n",
    "        if self.training:\n",
    "            def mean_along_multiple_dimensions(tensor, dims):\n",
    "                for i, dim in enumerate(np.sort(dims)):\n",
    "                    tensor = torch.mean(tensor, dim=int(dim - i))\n",
    "                return tensor\n",
    "\n",
    "            real_means = mean_along_multiple_dimensions(real, dims=[0, 2, 3])\n",
    "            imag_means = mean_along_multiple_dimensions(imag, dims=[0, 2, 3])\n",
    "\n",
    "            self.running_mean_real = self.running_mean_real * self.momentum + (1.0 - self.momentum) * real_means.data\n",
    "            self.running_mean_imag = self.running_mean_imag * self.momentum + (1.0 - self.momentum) * imag_means.data\n",
    "\n",
    "            real_means = real_means.unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "            imag_means = imag_means.unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "            real_centered = real - real_means\n",
    "            imag_centered = imag - imag_means\n",
    "\n",
    "            def sum_along_multiple_dimensions(tensor, dims):\n",
    "                for i, dim in enumerate(np.sort(dims)):\n",
    "                    tensor = torch.sum(tensor, dim=int(dim - i))\n",
    "                return tensor\n",
    "\n",
    "            Vrr = mean_along_multiple_dimensions(real_centered * real_centered, dims=[0, 2, 3]) + self.epsilon\n",
    "            Vri = mean_along_multiple_dimensions(real_centered * imag_centered, dims=[0, 2, 3])\n",
    "            Vii = mean_along_multiple_dimensions(imag_centered * imag_centered, dims=[0, 2, 3]) + self.epsilon\n",
    "\n",
    "            self.running_Vrr = self.running_Vrr * self.momentum + (1.0 - self.momentum) * Vrr.data\n",
    "            self.running_Vri = self.running_Vri * self.momentum + (1.0 - self.momentum) * Vri.data\n",
    "            self.running_Vii = self.running_Vii * self.momentum + (1.0 - self.momentum) * Vii.data\n",
    "\n",
    "            self.num_batches_tracked += 1\n",
    "\n",
    "\n",
    "        else:\n",
    "            real_means = Variable(self.running_mean_real.unsqueeze(0).unsqueeze(-1).unsqueeze(-1), requires_grad=False)\n",
    "            imag_means = Variable(self.running_mean_imag.unsqueeze(0).unsqueeze(-1).unsqueeze(-1), requires_grad=False)\n",
    "\n",
    "            Vrr = Variable(self.running_Vrr, requires_grad=False)\n",
    "            Vri = Variable(self.running_Vri, requires_grad=False)\n",
    "            Vii = Variable(self.running_Vii, requires_grad=False)\n",
    "\n",
    "            real_centered = real - real_means\n",
    "            imag_centered = imag - imag_means\n",
    "\n",
    "        tau = Vrr + Vii\n",
    "        delta = (Vrr * Vii) - (Vri ** 2)\n",
    "        s = torch.sqrt(delta)\n",
    "        t = torch.sqrt(tau + 2 * s)\n",
    "\n",
    "        inverse_st = 1.0 / (float(np.sqrt(2.0)) * s * t)\n",
    "        Wrr = (Vii + s) * inverse_st\n",
    "        Wii = (Vrr + s) * inverse_st\n",
    "        Wri = -Vri * inverse_st\n",
    "\n",
    "        Wrr = Wrr.unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "        Wri = Wri.unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "        Wii = Wii.unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        real_normed = Wrr * real_centered + Wri * imag_centered\n",
    "        imag_normed = Wri * real_centered + Wii * imag_centered\n",
    "\n",
    "        if self.check:\n",
    "            result_real_means = mean_along_multiple_dimensions(real_normed, dims=[0, 2, 3])\n",
    "            result_imag_means = mean_along_multiple_dimensions(imag_normed, dims=[0, 2, 3])\n",
    "\n",
    "            print(\"real part of result means: \", result_real_means)\n",
    "            print(\"imag part of result means: \", result_imag_means)\n",
    "\n",
    "            Vrr = mean_along_multiple_dimensions(real_normed * real_normed, dims=[0, 2, 3]) + self.epsilon\n",
    "            Vri = mean_along_multiple_dimensions(real_normed * imag_normed, dims=[0, 2, 3])\n",
    "            Vii = mean_along_multiple_dimensions(imag_normed * imag_normed, dims=[0, 2, 3]) + self.epsilon\n",
    "\n",
    "            print('covariance: ', Vrr + Vii)\n",
    "\n",
    "            print('real part of relation: ', Vrr - Vii)\n",
    "            print('iamg part of relation: ', 2 * Vri)\n",
    "\n",
    "        gamma_rr = self.gamma_rr.unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "        gamma_ri = self.gamma_ri.unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "        gamma_ii = self.gamma_ii.unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        bias_real = self.bias_real.unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "        bias_imag = self.bias_imag.unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "        ans_real = real_normed * gamma_rr + imag_normed * gamma_ri + bias_real\n",
    "        ans_imag = real_normed * gamma_ri + imag_normed * gamma_ii + bias_imag\n",
    "        # print(ans_real.shape)\n",
    "        # print(ans_imag.shape)\n",
    "        return Complex(ans_real, ans_imag)\n",
    "\n",
    "\n",
    "class C_Linear(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(C_Linear, self).__init__()\n",
    "        self.weight_real = nn.Parameter(nn.Linear(in_dim, out_dim).weight.data, requires_grad=True)\n",
    "        self.weight_imag = nn.Parameter(nn.Linear(in_dim, out_dim).weight.data, requires_grad=True)\n",
    "\n",
    "    def forward(self, complex):\n",
    "        x_ = F.linear(complex.real, self.weight_real) - F.linear(complex.imag, self.weight_imag)\n",
    "        y_ = F.linear(complex.real, self.weight_imag) + F.linear(complex.imag, self.weight_real)\n",
    "        return Complex(x_, y_)\n",
    "\n",
    "\n",
    "class C_ReLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(C_ReLU, self).__init__()\n",
    "\n",
    "    def forward(self, complex):\n",
    "        return Complex(F.relu(complex.real), F.relu(complex.imag))\n",
    "\n",
    "\n",
    "class C_LeakyReLU(nn.Module):\n",
    "    def __init__(self, alpha=0.001):\n",
    "        super(C_LeakyReLU, self).__init__()\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, complex):\n",
    "        return Complex(F.leaky_relu(complex.real, self.alpha), F.leaky_relu(complex.imag, self.alpha))\n",
    "\n",
    "\n",
    "class Mod_ReLU(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(Mod_ReLU, self).__init__()\n",
    "        self.b = nn.Parameter(torch.FloatTensor(channels).fill_(0), requires_grad=True)\n",
    "\n",
    "    def forward(self, complex):\n",
    "        mag = complex.mag()\n",
    "        if len(mag.shape) > 2:\n",
    "            mag = F.relu(mag + self.b[None, :, None, None])\n",
    "        else:\n",
    "            mag = F.relu(mag + self.b[None, :])\n",
    "        res = Complex()\n",
    "        res.from_polar(mag, complex.phase())\n",
    "        return res\n",
    "\n",
    "\n",
    "def complex_weight_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('C_Linear') != -1:\n",
    "        # real weigths\n",
    "        fan_in_real, fan_out_real = nn.init._calculate_fan_in_and_fan_out(m.weight_real.data)\n",
    "        s_real = 1. / (fan_in_real + fan_out_real)  # glorot or xavier criterion\n",
    "        rng_real = np.random.RandomState(999)\n",
    "        modulus_real = rng_real.rayleigh(scale=s_real, size=m.weight_real.data.shape)\n",
    "        phase_real = rng_real.uniform(low=-np.pi, high=np.pi, size=m.weight_real.data.shape)\n",
    "        weight_real = torch.from_numpy(modulus_real) * torch.cos(torch.from_numpy(phase_real))\n",
    "        # imag weights\n",
    "        fan_in_imag, fan_out_imag = nn.init._calculate_fan_in_and_fan_out(m.weight_imag.data)\n",
    "        s_imag = 1. / (fan_in_imag + fan_out_imag)  # glorot or xavier criterion\n",
    "        rng_imag = np.random.RandomState(999)\n",
    "        modulus_imag = rng_imag.rayleigh(scale=s_imag, size=m.weight_imag.data.shape)\n",
    "        phase_imag = rng_imag.uniform(low=-np.pi, high=np.pi, size=m.weight_imag.data.shape)\n",
    "        weight_imag = torch.from_numpy(modulus_imag) * torch.cos(torch.from_numpy(phase_imag))\n",
    "\n",
    "    if classname.find('C_conv2d') != -1:\n",
    "        # real weigths\n",
    "        fan_in_real, fan_out_real = nn.init._calculate_fan_in_and_fan_out(m.weight_real.data)\n",
    "        s_real = 1. / (fan_in_real + fan_out_real)  # glorot or xavier criterion\n",
    "        rng_real = np.random.RandomState(999)\n",
    "        modulus_real = rng_real.rayleigh(scale=s_real, size=m.weight_real.data.shape)\n",
    "        phase_real = rng_real.uniform(low=-np.pi, high=np.pi, size=m.weight_real.data.shape)\n",
    "        weight_real = torch.from_numpy(modulus_real) * torch.cos(torch.from_numpy(phase_real))\n",
    "        # imag weights\n",
    "        fan_in_imag, fan_out_imag = nn.init._calculate_fan_in_and_fan_out(m.weight_imag.data)\n",
    "        s_imag = 1. / (fan_in_imag + fan_out_imag)  # glorot or xavier criterion\n",
    "        rng_imag = np.random.RandomState(999)\n",
    "        modulus_imag = rng_imag.rayleigh(scale=s_imag, size=m.weight_imag.data.shape)\n",
    "        phase_imag = rng_imag.uniform(low=-np.pi, high=np.pi, size=m.weight_imag.data.shape)\n",
    "        weight_imag = torch.from_numpy(modulus_imag) * torch.cos(torch.from_numpy(phase_imag))\n",
    "\n",
    "    if classname.find('C_BatchNorm2d') != -1:\n",
    "        # real weigths\n",
    "        fan_in_real, fan_out_real = nn.init._calculate_fan_in_and_fan_out(m.weight_real.data)\n",
    "        s_real = 1. / (fan_in_real + fan_out_real)  # glorot or xavier criterion\n",
    "        rng_real = np.random.RandomState(999)\n",
    "        modulus_real = rng_real.rayleigh(scale=s_real, size=m.weight_real.data.shape)\n",
    "        phase_real = rng_real.uniform(low=-np.pi, high=np.pi, size=m.weight_real.data.shape)\n",
    "        weight_real = torch.from_numpy(modulus_real) * torch.cos(torch.from_numpy(phase_real))\n",
    "        # imag weights\n",
    "        fan_in_imag, fan_out_imag = nn.init._calculate_fan_in_and_fan_out(m.weight_imag.data)\n",
    "        s_imag = 1. / (fan_in_imag + fan_out_imag)  # glorot or xavier criterion\n",
    "        rng_imag = np.random.RandomState(999)\n",
    "        modulus_imag = rng_imag.rayleigh(scale=s_imag, size=m.weight_imag.data.shape)\n",
    "        phase_imag = rng_imag.uniform(low=-np.pi, high=np.pi, size=m.weight_imag.data.shape)\n",
    "        weight_imag = torch.from_numpy(modulus_imag) * torch.cos(torch.from_numpy(phase_imag))\n",
    "\n",
    "\n",
    "class Sample(nn.Module):\n",
    "    \"\"\"\n",
    "    Foo model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Sample, self).__init__()\n",
    "        self.conv1 = C_convtranspose2d(3, 3, 3, 1, 1)\n",
    "        self.relu = C_ReLU()\n",
    "        self.conv2 = C_convtranspose2d(3, 3, 3, 1, 1)\n",
    "        self.mod_relu = Mod_ReLU(3)\n",
    "        self.conv3 = C_convtranspose2d(3, 3, 3, 1, 1)\n",
    "\n",
    "    def forward(self, complex):\n",
    "        complex = self.conv1(complex)\n",
    "        complex = self.relu(complex)\n",
    "        complex = self.conv2(complex)\n",
    "        complex = self.mod_relu(complex)\n",
    "        return self.conv3(complex)\n",
    "\n",
    "\n",
    "def test_1():\n",
    "    from torch import optim\n",
    "    a = Variable(torch.rand(2, 3, 5, 5), requires_grad=True)\n",
    "    b = Variable(torch.rand(2, 3, 5, 5), requires_grad=True)\n",
    "    complex = Complex(a, b)\n",
    "    conv1 = C_conv2d(3, 3, 3, 1, 1)\n",
    "    complex_weight_init(conv1)  # conv layer weight init.\n",
    "    prev = list(conv1.parameters())[0].clone()\n",
    "    res = conv1(complex)\n",
    "    optimizer = optim.Adam(conv1.parameters(), 0.1)\n",
    "    foo = Variable(torch.rand(2, 3, 5, 5))\n",
    "    for i in range(10):\n",
    "        complex_res = conv1(complex)\n",
    "        loss = F.mse_loss(complex_res.mag(), foo)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def test_2():\n",
    "    from torch import optim\n",
    "    import numpy as np\n",
    "    a = torch.rand(2, 3, 5, 5)\n",
    "    b = torch.rand(2, 3, 5, 5)\n",
    "    complex = Complex(a, b)\n",
    "    model = Sample()\n",
    "    model.apply(complex_weight_init)  # apply complex weights initialization\n",
    "    parameters_start = [p.clone() for p in model.parameters()]\n",
    "    prev = list(model.parameters())[0].clone()\n",
    "    optimizer = optim.Adam(model.parameters(), 0.1)\n",
    "    foo = Variable(torch.rand(2, 3, 5, 5))\n",
    "    for i in range(10):\n",
    "        complex_res = model(complex)\n",
    "        loss = F.mse_loss(complex_res.mag(), foo)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    for l1, l2 in zip(parameters_start, list(model.parameters())):\n",
    "        assert np.array_equal(l1.cpu().data.numpy(), l2.cpu().data.numpy()) == False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class InitialBlock(nn.Module):\n",
    "    \"\"\"The initial block is composed of two branches:\n",
    "    1. a main branch which performs a regular convolution with stride 2;\n",
    "    2. an extension branch which performs max-pooling.\n",
    "    Doing both operations in parallel and concatenating their results\n",
    "    allows for efficient downsampling and expansion. The main branch\n",
    "    outputs 13 feature maps while the extension branch outputs 3, for a\n",
    "    total of 16 feature maps after concatenation.\n",
    "    Keyword arguments:\n",
    "    - in_channels (int): the number of input channels.\n",
    "    - out_channels (int): the number output channels.\n",
    "    - kernel_size (int, optional): the kernel size of the filters used in\n",
    "    the convolution layer. Default: 3.\n",
    "    - padding (int, optional): zero-padding added to both sides of the\n",
    "    input. Default: 0.\n",
    "    - bias (bool, optional): Adds a learnable bias to the output if\n",
    "    ``True``. Default: False.\n",
    "    - relu (bool, optional): When ``True`` ReLU is used as the activation\n",
    "    function; otherwise, PReLU is used. Default: True.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 bias=False,\n",
    "                 relu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        if relu:\n",
    "            activation = nn.ReLU\n",
    "        else:\n",
    "            activation = nn.PReLU\n",
    "\n",
    "        # Main branch - As stated above the number of output channels for this\n",
    "        # branch is the total minus 3, since the remaining channels come from\n",
    "        # the extension branch\n",
    "        self.main_branch = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels - in_channels,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            bias=bias)\n",
    "\n",
    "        # Extension branch\n",
    "        self.ext_branch = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "\n",
    "        # Initialize batch normalization to be used after concatenation\n",
    "        self.batch_norm = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # PReLU layer to apply after concatenating the branches\n",
    "        self.out_activation = activation()\n",
    "\n",
    "    def forward(self, x):\n",
    "        main = self.main_branch(x)\n",
    "        ext = self.ext_branch(x)\n",
    "\n",
    "        # Concatenate branches\n",
    "        out = torch.cat((main, ext), 1)\n",
    "\n",
    "        # Apply batch normalization\n",
    "        out = self.batch_norm(out)\n",
    "\n",
    "        return self.out_activation(out)\n",
    "\n",
    "\n",
    "class RegularBottleneck(nn.Module):\n",
    "    \"\"\"Regular bottlenecks are the main building block of ENet.\n",
    "    Main branch:\n",
    "    1. Shortcut connection.\n",
    "    Extension branch:\n",
    "    1. 1x1 convolution which decreases the number of channels by\n",
    "    ``internal_ratio``, also called a projection;\n",
    "    2. regular, dilated or asymmetric convolution;\n",
    "    3. 1x1 convolution which increases the number of channels back to\n",
    "    ``channels``, also called an expansion;\n",
    "    4. dropout as a regularizer.\n",
    "    Keyword arguments:\n",
    "    - channels (int): the number of input and output channels.\n",
    "    - internal_ratio (int, optional): a scale factor applied to\n",
    "    ``channels`` used to compute the number of\n",
    "    channels after the projection. eg. given ``channels`` equal to 128 and\n",
    "    internal_ratio equal to 2 the number of channels after the projection\n",
    "    is 64. Default: 4.\n",
    "    - kernel_size (int, optional): the kernel size of the filters used in\n",
    "    the convolution layer described above in item 2 of the extension\n",
    "    branch. Default: 3.\n",
    "    - padding (int, optional): zero-padding added to both sides of the\n",
    "    input. Default: 0.\n",
    "    - dilation (int, optional): spacing between kernel elements for the\n",
    "    convolution described in item 2 of the extension branch. Default: 1.\n",
    "    asymmetric (bool, optional): flags if the convolution described in\n",
    "    item 2 of the extension branch is asymmetric or not. Default: False.\n",
    "    - dropout_prob (float, optional): probability of an element to be\n",
    "    zeroed. Default: 0 (no dropout).\n",
    "    - bias (bool, optional): Adds a learnable bias to the output if\n",
    "    ``True``. Default: False.\n",
    "    - relu (bool, optional): When ``True`` ReLU is used as the activation\n",
    "    function; otherwise, PReLU is used. Default: True.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 channels,\n",
    "                 internal_ratio=4,\n",
    "                 kernel_size=3,\n",
    "                 padding=0,\n",
    "                 dilation=1,\n",
    "                 asymmetric=False,\n",
    "                 dropout_prob=0,\n",
    "                 bias=False,\n",
    "                 relu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Check in the internal_scale parameter is within the expected range\n",
    "        # [1, channels]\n",
    "        if internal_ratio <= 1 or internal_ratio > channels:\n",
    "            raise RuntimeError(\"Value out of range. Expected value in the \"\n",
    "                               \"interval [1, {0}], got internal_scale={1}.\"\n",
    "                               .format(channels, internal_ratio))\n",
    "\n",
    "        internal_channels = channels // internal_ratio\n",
    "\n",
    "        if relu:\n",
    "            activation = nn.ReLU\n",
    "        else:\n",
    "            activation = nn.PReLU\n",
    "\n",
    "        # Main branch - shortcut connection\n",
    "\n",
    "        # Extension branch - 1x1 convolution, followed by a regular, dilated or\n",
    "        # asymmetric convolution, followed by another 1x1 convolution, and,\n",
    "        # finally, a regularizer (spatial dropout). Number of channels is constant.\n",
    "\n",
    "        # 1x1 projection convolution\n",
    "        self.ext_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                channels,\n",
    "                internal_channels,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                bias=bias), nn.BatchNorm2d(internal_channels), activation())\n",
    "\n",
    "        # If the convolution is asymmetric we split the main convolution in\n",
    "        # two. Eg. for a 5x5 asymmetric convolution we have two convolution:\n",
    "        # the first is 5x1 and the second is 1x5.\n",
    "        if asymmetric:\n",
    "            self.ext_conv2 = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    internal_channels,\n",
    "                    internal_channels,\n",
    "                    kernel_size=(kernel_size, 1),\n",
    "                    stride=1,\n",
    "                    padding=(padding, 0),\n",
    "                    dilation=dilation,\n",
    "                    bias=bias), nn.BatchNorm2d(internal_channels), activation(),\n",
    "                nn.Conv2d(\n",
    "                    internal_channels,\n",
    "                    internal_channels,\n",
    "                    kernel_size=(1, kernel_size),\n",
    "                    stride=1,\n",
    "                    padding=(0, padding),\n",
    "                    dilation=dilation,\n",
    "                    bias=bias), nn.BatchNorm2d(internal_channels), activation())\n",
    "        else:\n",
    "            self.ext_conv2 = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    internal_channels,\n",
    "                    internal_channels,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=1,\n",
    "                    padding=padding,\n",
    "                    dilation=dilation,\n",
    "                    bias=bias), nn.BatchNorm2d(internal_channels), activation())\n",
    "\n",
    "        # 1x1 expansion convolution\n",
    "        self.ext_conv3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                internal_channels,\n",
    "                channels,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                bias=bias), nn.BatchNorm2d(channels), activation())\n",
    "\n",
    "        self.ext_regul = nn.Dropout2d(p=dropout_prob)\n",
    "\n",
    "        # PReLU layer to apply after adding the branches\n",
    "        self.out_activation = activation()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Main branch shortcut\n",
    "        main = x\n",
    "\n",
    "        # Extension branch\n",
    "        ext = self.ext_conv1(x)\n",
    "        ext = self.ext_conv2(ext)\n",
    "        ext = self.ext_conv3(ext)\n",
    "        ext = self.ext_regul(ext)\n",
    "\n",
    "        # Add main and extension branches\n",
    "        out = main + ext\n",
    "\n",
    "        return self.out_activation(out)\n",
    "\n",
    "\n",
    "class DownsamplingBottleneck(nn.Module):\n",
    "    \"\"\"Downsampling bottlenecks further downsample the feature map size.\n",
    "    Main branch:\n",
    "    1. max pooling with stride 2; indices are saved to be used for\n",
    "    unpooling later.\n",
    "    Extension branch:\n",
    "    1. 2x2 convolution with stride 2 that decreases the number of channels\n",
    "    by ``internal_ratio``, also called a projection;\n",
    "    2. regular convolution (by default, 3x3);\n",
    "    3. 1x1 convolution which increases the number of channels to\n",
    "    ``out_channels``, also called an expansion;\n",
    "    4. dropout as a regularizer.\n",
    "    Keyword arguments:\n",
    "    - in_channels (int): the number of input channels.\n",
    "    - out_channels (int): the number of output channels.\n",
    "    - internal_ratio (int, optional): a scale factor applied to ``channels``\n",
    "    used to compute the number of channels after the projection. eg. given\n",
    "    ``channels`` equal to 128 and internal_ratio equal to 2 the number of\n",
    "    channels after the projection is 64. Default: 4.\n",
    "    - return_indices (bool, optional):  if ``True``, will return the max\n",
    "    indices along with the outputs. Useful when unpooling later.\n",
    "    - dropout_prob (float, optional): probability of an element to be\n",
    "    zeroed. Default: 0 (no dropout).\n",
    "    - bias (bool, optional): Adds a learnable bias to the output if\n",
    "    ``True``. Default: False.\n",
    "    - relu (bool, optional): When ``True`` ReLU is used as the activation\n",
    "    function; otherwise, PReLU is used. Default: True.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 internal_ratio=4,\n",
    "                 return_indices=False,\n",
    "                 dropout_prob=0,\n",
    "                 bias=False,\n",
    "                 relu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Store parameters that are needed later\n",
    "        self.return_indices = return_indices\n",
    "\n",
    "        # Check in the internal_scale parameter is within the expected range\n",
    "        # [1, channels]\n",
    "        if internal_ratio <= 1 or internal_ratio > in_channels:\n",
    "            raise RuntimeError(\"Value out of range. Expected value in the \"\n",
    "                               \"interval [1, {0}], got internal_scale={1}. \"\n",
    "                               .format(in_channels, internal_ratio))\n",
    "\n",
    "        internal_channels = in_channels // internal_ratio\n",
    "\n",
    "        if relu:\n",
    "            activation = nn.ReLU\n",
    "        else:\n",
    "            activation = nn.PReLU\n",
    "\n",
    "        # Main branch - max pooling followed by feature map (channels) padding\n",
    "        self.main_max1 = nn.MaxPool2d(\n",
    "            2,\n",
    "            stride=2,\n",
    "            return_indices=return_indices)\n",
    "\n",
    "        # Extension branch - 2x2 convolution, followed by a regular, dilated or\n",
    "        # asymmetric convolution, followed by another 1x1 convolution. Number\n",
    "        # of channels is doubled.\n",
    "\n",
    "        # 2x2 projection convolution with stride 2\n",
    "        self.ext_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels,\n",
    "                internal_channels,\n",
    "                kernel_size=2,\n",
    "                stride=2,\n",
    "                bias=bias), nn.BatchNorm2d(internal_channels), activation())\n",
    "\n",
    "        # Convolution\n",
    "        self.ext_conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                internal_channels,\n",
    "                internal_channels,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "                bias=bias), nn.BatchNorm2d(internal_channels), activation())\n",
    "\n",
    "        # 1x1 expansion convolution\n",
    "        self.ext_conv3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                internal_channels,\n",
    "                out_channels,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                bias=bias), nn.BatchNorm2d(out_channels), activation())\n",
    "\n",
    "        self.ext_regul = nn.Dropout2d(p=dropout_prob)\n",
    "\n",
    "        # PReLU layer to apply after concatenating the branches\n",
    "        self.out_activation = activation()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Main branch shortcut\n",
    "        if self.return_indices:\n",
    "            main, max_indices = self.main_max1(x)\n",
    "        else:\n",
    "            main = self.main_max1(x)\n",
    "\n",
    "        # Extension branch\n",
    "        ext = self.ext_conv1(x)\n",
    "        ext = self.ext_conv2(ext)\n",
    "        ext = self.ext_conv3(ext)\n",
    "        ext = self.ext_regul(ext)\n",
    "\n",
    "        # Main branch channel padding\n",
    "        n, ch_ext, h, w = ext.size()\n",
    "        ch_main = main.size()[1]\n",
    "        padding = torch.zeros(n, ch_ext - ch_main, h, w)\n",
    "\n",
    "        # Before concatenating, check if main is on the CPU or GPU and\n",
    "        # convert padding accordingly\n",
    "        if main.is_cuda:\n",
    "            padding = padding.cuda()\n",
    "\n",
    "        # Concatenate\n",
    "        main = torch.cat((main, padding), 1)\n",
    "\n",
    "        # Add main and extension branches\n",
    "        out = main + ext\n",
    "\n",
    "        return self.out_activation(out), max_indices\n",
    "\n",
    "\n",
    "class UpsamplingBottleneck(nn.Module):\n",
    "    \"\"\"The upsampling bottlenecks upsample the feature map resolution using max\n",
    "    pooling indices stored from the corresponding downsampling bottleneck.\n",
    "    Main branch:\n",
    "    1. 1x1 convolution with stride 1 that decreases the number of channels by\n",
    "    ``internal_ratio``, also called a projection;\n",
    "    2. max unpool layer using the max pool indices from the corresponding\n",
    "    downsampling max pool layer.\n",
    "    Extension branch:\n",
    "    1. 1x1 convolution with stride 1 that decreases the number of channels by\n",
    "    ``internal_ratio``, also called a projection;\n",
    "    2. transposed convolution (by default, 3x3);\n",
    "    3. 1x1 convolution which increases the number of channels to\n",
    "    ``out_channels``, also called an expansion;\n",
    "    4. dropout as a regularizer.\n",
    "    Keyword arguments:\n",
    "    - in_channels (int): the number of input channels.\n",
    "    - out_channels (int): the number of output channels.\n",
    "    - internal_ratio (int, optional): a scale factor applied to ``in_channels``\n",
    "     used to compute the number of channels after the projection. eg. given\n",
    "     ``in_channels`` equal to 128 and ``internal_ratio`` equal to 2 the number\n",
    "     of channels after the projection is 64. Default: 4.\n",
    "    - dropout_prob (float, optional): probability of an element to be zeroed.\n",
    "    Default: 0 (no dropout).\n",
    "    - bias (bool, optional): Adds a learnable bias to the output if ``True``.\n",
    "    Default: False.\n",
    "    - relu (bool, optional): When ``True`` ReLU is used as the activation\n",
    "    function; otherwise, PReLU is used. Default: True.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 internal_ratio=4,\n",
    "                 dropout_prob=0,\n",
    "                 bias=False,\n",
    "                 relu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Check in the internal_scale parameter is within the expected range\n",
    "        # [1, channels]\n",
    "        if internal_ratio <= 1 or internal_ratio > in_channels:\n",
    "            raise RuntimeError(\"Value out of range. Expected value in the \"\n",
    "                               \"interval [1, {0}], got internal_scale={1}. \"\n",
    "                               .format(in_channels, internal_ratio))\n",
    "\n",
    "        internal_channels = in_channels // internal_ratio\n",
    "\n",
    "        if relu:\n",
    "            activation = nn.ReLU\n",
    "        else:\n",
    "            activation = nn.PReLU\n",
    "\n",
    "        # Main branch - max pooling followed by feature map (channels) padding\n",
    "        self.main_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=bias),\n",
    "            nn.BatchNorm2d(out_channels))\n",
    "\n",
    "        # Remember that the stride is the same as the kernel_size, just like\n",
    "        # the max pooling layers\n",
    "        self.main_unpool1 = nn.MaxUnpool2d(kernel_size=2)\n",
    "\n",
    "        # Extension branch - 1x1 convolution, followed by a regular, dilated or\n",
    "        # asymmetric convolution, followed by another 1x1 convolution. Number\n",
    "        # of channels is doubled.\n",
    "\n",
    "        # 1x1 projection convolution with stride 1\n",
    "        self.ext_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels, internal_channels, kernel_size=1, bias=bias),\n",
    "            nn.BatchNorm2d(internal_channels), activation())\n",
    "\n",
    "        # Transposed convolution\n",
    "        self.ext_tconv1 = nn.ConvTranspose2d(\n",
    "            internal_channels,\n",
    "            internal_channels,\n",
    "            kernel_size=2,\n",
    "            stride=2,\n",
    "            bias=bias)\n",
    "        self.ext_tconv1_bnorm = nn.BatchNorm2d(internal_channels)\n",
    "        self.ext_tconv1_activation = activation()\n",
    "\n",
    "        # 1x1 expansion convolution\n",
    "        self.ext_conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                internal_channels, out_channels, kernel_size=1, bias=bias),\n",
    "            nn.BatchNorm2d(out_channels), activation())\n",
    "\n",
    "        self.ext_regul = nn.Dropout2d(p=dropout_prob)\n",
    "\n",
    "        # PReLU layer to apply after concatenating the branches\n",
    "        self.out_activation = activation()\n",
    "\n",
    "    def forward(self, x, max_indices, output_size):\n",
    "        # Main branch shortcut\n",
    "        main = self.main_conv1(x)\n",
    "        main = self.main_unpool1(\n",
    "            main, max_indices, output_size=output_size)\n",
    "\n",
    "        # Extension branch\n",
    "        ext = self.ext_conv1(x)\n",
    "        ext = self.ext_tconv1(ext, output_size=output_size)\n",
    "        ext = self.ext_tconv1_bnorm(ext)\n",
    "        ext = self.ext_tconv1_activation(ext)\n",
    "        ext = self.ext_conv2(ext)\n",
    "        ext = self.ext_regul(ext)\n",
    "\n",
    "        # Add main and extension branches\n",
    "        out = main + ext\n",
    "\n",
    "        return self.out_activation(out)\n",
    "\n",
    "\n",
    "class ENet(nn.Module):\n",
    "    \"\"\"Generate the ENet model.\n",
    "    Keyword arguments:\n",
    "    - num_classes (int): the number of classes to segment.\n",
    "    - encoder_relu (bool, optional): When ``True`` ReLU is used as the\n",
    "    activation function in the encoder blocks/layers; otherwise, PReLU\n",
    "    is used. Default: False.\n",
    "    - decoder_relu (bool, optional): When ``True`` ReLU is used as the\n",
    "    activation function in the decoder blocks/layers; otherwise, PReLU\n",
    "    is used. Default: True.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,input_channel, num_classes, encoder_relu=False, decoder_relu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.initial_block = InitialBlock(input_channel, 16, relu=encoder_relu)\n",
    "\n",
    "        # Stage 1 - Encoder\n",
    "        self.downsample1_0 = DownsamplingBottleneck(\n",
    "            16,\n",
    "            64,\n",
    "            return_indices=True,\n",
    "            dropout_prob=0.01,\n",
    "            relu=encoder_relu)\n",
    "        self.regular1_1 = RegularBottleneck(\n",
    "            64, padding=1, dropout_prob=0.01, relu=encoder_relu)\n",
    "        self.regular1_2 = RegularBottleneck(\n",
    "            64, padding=1, dropout_prob=0.01, relu=encoder_relu)\n",
    "        self.regular1_3 = RegularBottleneck(\n",
    "            64, padding=1, dropout_prob=0.01, relu=encoder_relu)\n",
    "        self.regular1_4 = RegularBottleneck(\n",
    "            64, padding=1, dropout_prob=0.01, relu=encoder_relu)\n",
    "\n",
    "        # Stage 2 - Encoder\n",
    "        self.downsample2_0 = DownsamplingBottleneck(\n",
    "            64,\n",
    "            128,\n",
    "            return_indices=True,\n",
    "            dropout_prob=0.1,\n",
    "            relu=encoder_relu)\n",
    "        self.regular2_1 = RegularBottleneck(\n",
    "            128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.dilated2_2 = RegularBottleneck(\n",
    "            128, dilation=2, padding=2, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.asymmetric2_3 = RegularBottleneck(\n",
    "            128,\n",
    "            kernel_size=5,\n",
    "            padding=2,\n",
    "            asymmetric=True,\n",
    "            dropout_prob=0.1,\n",
    "            relu=encoder_relu)\n",
    "        self.dilated2_4 = RegularBottleneck(\n",
    "            128, dilation=4, padding=4, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.regular2_5 = RegularBottleneck(\n",
    "            128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.dilated2_6 = RegularBottleneck(\n",
    "            128, dilation=8, padding=8, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.asymmetric2_7 = RegularBottleneck(\n",
    "            128,\n",
    "            kernel_size=5,\n",
    "            asymmetric=True,\n",
    "            padding=2,\n",
    "            dropout_prob=0.1,\n",
    "            relu=encoder_relu)\n",
    "        self.dilated2_8 = RegularBottleneck(\n",
    "            128, dilation=16, padding=16, dropout_prob=0.1, relu=encoder_relu)\n",
    "\n",
    "        # Stage 3 - Encoder\n",
    "        self.regular3_0 = RegularBottleneck(\n",
    "            128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.dilated3_1 = RegularBottleneck(\n",
    "            128, dilation=2, padding=2, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.asymmetric3_2 = RegularBottleneck(\n",
    "            128,\n",
    "            kernel_size=5,\n",
    "            padding=2,\n",
    "            asymmetric=True,\n",
    "            dropout_prob=0.1,\n",
    "            relu=encoder_relu)\n",
    "        self.dilated3_3 = RegularBottleneck(\n",
    "            128, dilation=4, padding=4, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.regular3_4 = RegularBottleneck(\n",
    "            128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.dilated3_5 = RegularBottleneck(\n",
    "            128, dilation=8, padding=8, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.asymmetric3_6 = RegularBottleneck(\n",
    "            128,\n",
    "            kernel_size=5,\n",
    "            asymmetric=True,\n",
    "            padding=2,\n",
    "            dropout_prob=0.1,\n",
    "            relu=encoder_relu)\n",
    "        self.dilated3_7 = RegularBottleneck(\n",
    "            128, dilation=16, padding=16, dropout_prob=0.1, relu=encoder_relu)\n",
    "\n",
    "        # Stage 4 - Decoder\n",
    "        self.upsample4_0 = UpsamplingBottleneck(\n",
    "            128, 64, dropout_prob=0.1, relu=decoder_relu)\n",
    "        self.regular4_1 = RegularBottleneck(\n",
    "            64, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
    "        self.regular4_2 = RegularBottleneck(\n",
    "            64, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
    "\n",
    "        # Stage 5 - Decoder\n",
    "        self.upsample5_0 = UpsamplingBottleneck(\n",
    "            64, 16, dropout_prob=0.1, relu=decoder_relu)\n",
    "        self.regular5_1 = RegularBottleneck(\n",
    "            16, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
    "        self.transposed_conv = nn.ConvTranspose2d(\n",
    "            16,\n",
    "            num_classes,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initial block\n",
    "        input_size = x.size()\n",
    "        x = self.initial_block(x)\n",
    "\n",
    "        # Stage 1 - Encoder\n",
    "        stage1_input_size = x.size()\n",
    "        x, max_indices1_0 = self.downsample1_0(x)\n",
    "        x = self.regular1_1(x)\n",
    "        x = self.regular1_2(x)\n",
    "        x = self.regular1_3(x)\n",
    "        x = self.regular1_4(x)\n",
    "\n",
    "        # Stage 2 - Encoder\n",
    "        stage2_input_size = x.size()\n",
    "        x, max_indices2_0 = self.downsample2_0(x)\n",
    "        x = self.regular2_1(x)\n",
    "        x = self.dilated2_2(x)\n",
    "        x = self.asymmetric2_3(x)\n",
    "        x = self.dilated2_4(x)\n",
    "        x = self.regular2_5(x)\n",
    "        x = self.dilated2_6(x)\n",
    "        x = self.asymmetric2_7(x)\n",
    "        x = self.dilated2_8(x)\n",
    "\n",
    "        # Stage 3 - Encoder\n",
    "        x = self.regular3_0(x)\n",
    "        x = self.dilated3_1(x)\n",
    "        x = self.asymmetric3_2(x)\n",
    "        x = self.dilated3_3(x)\n",
    "        x = self.regular3_4(x)\n",
    "        x = self.dilated3_5(x)\n",
    "        x = self.asymmetric3_6(x)\n",
    "        x = self.dilated3_7(x)\n",
    "\n",
    "        # Stage 4 - Decoder\n",
    "        x = self.upsample4_0(x, max_indices2_0, output_size=stage2_input_size)\n",
    "        x = self.regular4_1(x)\n",
    "        x = self.regular4_2(x)\n",
    "\n",
    "        # Stage 5 - Decoder\n",
    "        x = self.upsample5_0(x, max_indices1_0, output_size=stage1_input_size)\n",
    "        x = self.regular5_1(x)\n",
    "        x = self.transposed_conv(x, output_size=input_size)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "dataset={\"Bay\":[\"Bay_data.pt\",\"Bay_real_data.pt\",\"Bay_imag_data.pt\",\"Bay_label_5.pt\"],\n",
    "         \"fle\":[\"fle_data.pt\",\"fle_real_data.pt\",\"fle_imag_data.pt\",\"fle_label_11.pt\"]}\n",
    "DASETDIR=\"./input/dataset\"\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self,modeKey=\"Bay\", size=100, augment=1,):\n",
    "        super(Dataset, self).__init__()\n",
    "        pt_files=dataset[modeKey]\n",
    "        data0_real=self.pt2tensor(pt_files[0])\n",
    "        data0_imag=torch.zeros_like(data0_real)\n",
    "        data1_real=self.pt2tensor(pt_files[1])\n",
    "        data1_imag=self.pt2tensor(pt_files[2])\n",
    "        label=self.pt2tensor(pt_files[3])\n",
    "        self.data_real=torch.cat([data0_real,data1_real],dim=0)#.permute([0,2,1])\n",
    "        self.data_imag=torch.cat([data0_imag,data1_imag],dim=0)#.permute([0,2,1])\n",
    "        self.label=label.permute([1,0])\n",
    "        self.data_H=self.label.size(0)\n",
    "        self.data_W=self.label.size(1)\n",
    "        self.size=size\n",
    "        self.aug=augment\n",
    "        h_s=np.linspace(0,self.data_H-size-30,30).astype(np.int)\n",
    "        w_s=np.linspace(0,self.data_W-size-30,30).astype(np.int)\n",
    "        self.index_s=[]\n",
    "        for h in h_s:\n",
    "            for w in w_s:\n",
    "                self.index_s.append((h,w))\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        i=index%len(self.index_s)\n",
    "        i_h=self.index_s[i][0]\n",
    "        i_w=self.index_s[i][1]\n",
    "        h=random.randint(0,30)+i_h\n",
    "        w=random.randint(0,30)+i_w\n",
    "        return self.data_real[:,h:h+self.size,w:w+self.size],self.data_imag[:,h:h+self.size,w:w+self.size],self.label[h:h+self.size,w:w+self.size]\n",
    "    def pt2tensor(self,path):\n",
    "        with open(os.path.join(DASETDIR, path),\"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "            return torch.from_numpy(data)\n",
    "    def __len__(self):\n",
    "        return 1200*self.aug#  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Foo model\n",
    "    \"\"\"\n",
    "    def __init__(self,num_class):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = C_conv2d(6, 64, 3, 1, 1)\n",
    "        self.lre1=C_LeakyReLU()\n",
    "        self.conv2 = C_conv2d(64, 8, 3, 1, 1)\n",
    "        self.enet=ENet(8,num_class)\n",
    "\n",
    "    def forward(self, complex):\n",
    "        complex = self.conv1(complex)\n",
    "        complex = self.lre1(complex)\n",
    "        complex = self.conv2(complex)\n",
    "        input=complex.real\n",
    "        out=self.enet(input)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> \n",
      "===> \n",
      "===> \n",
      "===>  \n",
      "===> \n",
      "===> \n",
      ": 0.9736028645833333\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": 0.9570390271493213\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam,lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "N_EPOCH=1000#\n",
    "LR=0.1#\n",
    "GAMA=0.1#LR_DECAY\n",
    "LR_DECAY=[200,300,400,500,600]# EPOCH, GAMA\n",
    "BATCH_SIZE=16#\n",
    "ONLY_TEST=True#TRUEchekpoint\n",
    "CUDA=False\n",
    "ALLTEST=True# \n",
    "ISRESUME=False\n",
    "DATA_SIZE=100\n",
    "AUG=1\n",
    "def main():\n",
    "    print(\"===> \")\n",
    "    torch.set_grad_enabled(True)\n",
    "    model=CNN(12) #\n",
    "    model.apply(complex_weight_init)\n",
    "    if ONLY_TEST or ISRESUME:\n",
    "        model=torch.load(\"./checkpoint/model_best.pth\",map_location= torch.device('cpu'))\n",
    "        print(\"===> \")\n",
    "    if CUDA:\n",
    "        model=model.cuda()\n",
    "    criterion=nn.CrossEntropyLoss() #reduction='sum'\n",
    "    print(\"===> \")\n",
    "    full_dataset=Dataset(\"fle\",size=DATA_SIZE,augment=AUG)\n",
    "    train_set, val_set = torch.utils.data.random_split(full_dataset, [1100*AUG, 100*AUG])\n",
    "    #train_set = Dataset()\n",
    "    train_loader = DataLoader(dataset=train_set,num_workers=0,batch_size=BATCH_SIZE, shuffle=False)\n",
    "    #val_set=Dataset(istrain=False)\n",
    "    val_loader = DataLoader(dataset=val_set, num_workers=0, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    print(\"===>  \")\n",
    "    optimizer = Adam(model.parameters(), lr=LR)\n",
    "    scheduler = lr_scheduler.MultiStepLR(optimizer,LR_DECAY,gamma=GAMA)\n",
    "    print(\"===> \")\n",
    "    best_precision=0\n",
    "    loss_plt=[]\n",
    "    precision_plt=[]\n",
    "    if not ONLY_TEST:\n",
    "        for epoch in range(N_EPOCH):\n",
    "            loss_sum = 0\n",
    "            for i,batch in enumerate(train_loader):\n",
    "                real, imag, label = batch[0], batch[1], batch[2]\n",
    "                input = Complex(real, imag)\n",
    "                if CUDA:\n",
    "                    real=real.cuda()\n",
    "                    imag=imag.cuda()\n",
    "                    label=label.cuda()\n",
    "                    input = Complex(real, imag)\n",
    "                    input=input.cuda()\n",
    "                optimizer.zero_grad()\n",
    "                predict = model(input)\n",
    "                loss = criterion(predict, label)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss_sum+=loss.item()\n",
    "                #print(i,loss.item())\n",
    "            loss_plt.append(loss_sum)\n",
    "            plot(loss_plt,\"./loss.pdf\",\"LOSS\")\n",
    "            print(\"Epoch:\",epoch,\"Loss:\",loss_sum,\"LR:\",optimizer.param_groups[0][\"lr\"])\n",
    "            scheduler.step()\n",
    "            torch.set_grad_enabled(False)\n",
    "            if ALLTEST:\n",
    "                error_num=0\n",
    "                sum=0\n",
    "                input = Complex(full_dataset.data_real.unsqueeze(0), full_dataset.data_imag.unsqueeze(0))\n",
    "                if CUDA:\n",
    "                    input = Complex(full_dataset.data_real.unsqueeze(0).cuda(), full_dataset.data_imag.unsqueeze(0).cuda())\n",
    "                    input=input.cuda()\n",
    "                predict = model(input)\n",
    "                max_id = torch.argmax(predict, 1)\n",
    "                error_num_ = (full_dataset.label.unsqueeze(0) - max_id.cpu()).abs()\n",
    "                error_num_[error_num_ > 0] = 1\n",
    "                error_num += error_num_.sum()\n",
    "                sum = full_dataset.label.shape[0] * full_dataset.label.shape[1]\n",
    "                precision=(float(sum - error_num) / sum)\n",
    "                print(\"Epoch:\",epoch,\":\",precision)\n",
    "                if precision>best_precision:\n",
    "                    best_precision=precision\n",
    "                    save_checkpoint(model,epoch)\n",
    "                    plot_img(labeltoRGB(full_dataset.label.cpu()), \"label\")\n",
    "                    plot_img(labeltoRGB(max_id[0].cpu()), \"predict\")\n",
    "            else:\n",
    "                error_num=0\n",
    "                sum=0\n",
    "                for batch in val_loader:\n",
    "                    real, imag, label = batch[0], batch[1], batch[2]\n",
    "                    input = Complex(real, imag)\n",
    "                    if CUDA:\n",
    "                        real = real.cuda()\n",
    "                        imag = imag.cuda()\n",
    "                        label = label.cuda()\n",
    "                        input = Complex(real, imag)\n",
    "                        input = input.cuda()\n",
    "                    predict = model(input)\n",
    "                    max_id = torch.argmax(predict, 1)\n",
    "                    error_num_ = (label - max_id).abs()\n",
    "                    error_num_[error_num_ > 0] = 1\n",
    "                    error_num += error_num_.sum()\n",
    "                    sum += label.shape[0] * label.shape[1] * label.shape[2]\n",
    "                    #plot_img(labeltoRGB(label[0].cpu()), \"label\")\n",
    "                    #plot_img(labeltoRGB(max_id[0].cpu()), \"predict\")\n",
    "                precision=(float(sum - error_num) / sum)\n",
    "                print(\"Epoch:\",epoch,\":\",precision)\n",
    "                if precision>best_precision:\n",
    "                    best_precision=precision\n",
    "                    save_checkpoint(model,epoch)\n",
    "                    input = Complex(full_dataset.data_real.unsqueeze(0), full_dataset.data_imag.unsqueeze(0))\n",
    "                    if CUDA:\n",
    "                        input = Complex(full_dataset.data_real.unsqueeze(0).cuda(), full_dataset.data_imag.unsqueeze(0).cuda())\n",
    "                        input=input.cuda()\n",
    "                    predict = model(input)\n",
    "                    max_id = torch.argmax(predict, 1)\n",
    "                    plot_img(labeltoRGB(full_dataset.label.cpu()), \"label\")\n",
    "                    plot_img(labeltoRGB(max_id[0].cpu()), \"predict\")\n",
    "            precision_plt.append(precision)\n",
    "            plot(precision_plt,\"./precision.pdf\",\"PRECISION\")\n",
    "            torch.set_grad_enabled(True)\n",
    "    else:\n",
    "        print(\"===> \")\n",
    "        torch.set_grad_enabled(False)\n",
    "        error_num = 0\n",
    "        sum = 0\n",
    "        input = Complex(full_dataset.data_real.unsqueeze(0), full_dataset.data_imag.unsqueeze(0))\n",
    "        if CUDA:\n",
    "            input = Complex(full_dataset.data_real.unsqueeze(0).cuda(), full_dataset.data_imag.unsqueeze(0).cuda())\n",
    "            input=input.cuda()\n",
    "        predict = model(input)\n",
    "        max_id = torch.argmax(predict, 1)\n",
    "        max_id = torch.argmax(predict, 1)\n",
    "        error_num_ = (full_dataset.label.unsqueeze(0) - max_id.cpu()).abs()\n",
    "        error_num_[error_num_ > 0] = 1\n",
    "        error_num += error_num_.sum()\n",
    "        sum = full_dataset.label.shape[0] * full_dataset.label.shape[1]\n",
    "        precision=(float(sum - error_num) / sum)\n",
    "        print(\":\",precision)\n",
    "        plot_img(labeltoRGB(full_dataset.label.cpu()), \"label\")\n",
    "        plot_img(labeltoRGB(max_id[0].cpu()), \"predict\")\n",
    "        precision=(float(sum - error_num) / sum)\n",
    "        if not ALLTEST:\n",
    "            for batch in val_loader:\n",
    "                real, imag, label = batch[0], batch[1], batch[2]\n",
    "                input = Complex(real, imag)\n",
    "                if CUDA:\n",
    "                    real = real.cuda()\n",
    "                    imag = imag.cuda()\n",
    "                    label = label.cuda()\n",
    "                    input = Complex(real, imag)\n",
    "                    input = input.cuda()\n",
    "                predict = model(input)\n",
    "                max_id = torch.argmax(predict, 1)\n",
    "                error_num_ = (label - max_id).abs()\n",
    "                error_num_[error_num_ > 0] = 1\n",
    "                error_num += error_num_.sum()\n",
    "                sum += label.shape[0] * label.shape[1] * label.shape[2]\n",
    "                #for i in range(label.shape[0]):\n",
    "                    #plot_img(labeltoRGB(label[i].cpu()), \"label\")\n",
    "                    #plot_img(labeltoRGB(max_id[i].cpu()), \"predict\")\n",
    "            print(\":\", (float(sum - error_num) / sum))\n",
    "        torch.set_grad_enabled(True)\n",
    "def save_checkpoint(model, epoch):\n",
    "    if epoch % 10 == 0:\n",
    "        model_out_path = \"./checkpoint/\" + \"model_best.pth\"\n",
    "        if not os.path.exists(\"./checkpoint/\"):\n",
    "            os.makedirs(\"./checkpoint/\")\n",
    "        torch.save(model, model_out_path)\n",
    "def plot(data,name=\"./loss.pdf\",title=\"LOSS\"):\n",
    "    epoch=len(data)\n",
    "    axis = np.linspace(1, epoch, epoch)\n",
    "    label = title+' PICTURE'\n",
    "    fig = plt.figure()\n",
    "    plt.title(label)\n",
    "    plt.plot(\n",
    "        axis,\n",
    "        data,\n",
    "        label=title+'_EPOCH {}'.format(epoch)\n",
    "    )\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(title.lower())\n",
    "    plt.grid(True)\n",
    "    plt.savefig(name,dpi=200, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "def labeltoRGB(label):\n",
    "    RGB_list=[(255, 255, 255), (0, 0, 255), (255, 0, 0), (255, 255, 0), (0, 131, 74), (0, 255, 0), (183, 0, 255), (255, 128, 0),\n",
    "     (90, 11, 255), (0, 252, 255), (171, 138, 80), (191, 191, 255), (255, 182, 229), (191, 255, 191), (255, 217, 157),\n",
    "     (128, 0, 0)]\n",
    "    img=np.empty([label.shape[0],label.shape[1],3],dtype=np.uint8)\n",
    "    for i in range(label.shape[0]):\n",
    "        for j in range(label.shape[1]):\n",
    "            img[i,j]=RGB_list[label[i][j]]\n",
    "    img=Image.fromarray(img)\n",
    "    return img\n",
    "def plot_img(img,name):\n",
    "    #plt.ion()\n",
    "    img.save(\"./\"+name+\".jpeg\")\n",
    "    plt.figure(name)  # \n",
    "    plt.imshow(img)\n",
    "    plt.axis('on')  #  off\n",
    "    plt.title(name)  # \n",
    "    plt.show()\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "if __name__ == \"__main__\":\n",
    "    setup_seed(2)\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
